{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping GitHub Topics Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a website and describe your objective\n",
    "- Browse through different sites and pick on to scrape. Check the \"Project Ideas\" section for inspiration.\n",
    "- Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n",
    "- Summarize your project idea and outline your strategy in a Juptyer notebook. Use the \"New\" button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outline\n",
    "- Scrape website &#8594; https://datastackjobs.com\n",
    "- We will scrape the following content\n",
    "    - Company Name\n",
    "    - Job Title\n",
    "    - Location\n",
    "    - Tags or Skills\n",
    "    - Time Posted\n",
    "    - Job Type\n",
    "    - Category\n",
    "    - Job Url\n",
    "- We will then arrange the data in a tabular form and eport it to  CSV file\n",
    "- Output will look like\n",
    "\n",
    "Company Name,Job Title,Location,Tags or Skills,Time Posted,Job Type,Category,Job Url\n",
    "Boulevard,Sr. Product Analyst,United States. Remote,Amplitude | Mixpanel | SQL,a month ago,Full-Time,Product,https://datastackjobs.com/jobs/yifxlruwe2-sr-product-analyst\n",
    "\n",
    "Bitquery,Data Engineer/Data Ops,Worldwide . Remote,Airflow | Clickhouse | Apache Spark,2 months ago,Full-Time,Data Engineering,https://datastackjobs.com/jobs/ixumzawhqq-data-engineer-data-ops\n",
    "\n",
    "![datastack jobs](https://beeimg.com/images/i82872082642.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website --> https://datastackjobs.com/ has returned a response having status code --> 200.\n",
      "Read more about status code --> https://developer.mozilla.org/en-US/docs/Web/HTTP/Status\n",
      "response content stored in Web_Scrapping_content.html\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\"\"\"Import libraries if not then install them\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas\n",
    "import requests # to work with http and api requests\n",
    "from bs4 import BeautifulSoup # for parsing HTML, XML, JSON and other data\n",
    "\n",
    "# Config File\n",
    "config = {}\n",
    "config[\"base_url\"] = r\"https://datastackjobs.com\"\n",
    "config[\"status_code_info_url\"] = r\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status\"\n",
    "config[\"response_file_content\"] = \"Web_Scrapping_content.html\"\n",
    "\n",
    "# using requests library to fetch data from base_url\n",
    "response = requests.get(config[\"base_url\"])\n",
    "\n",
    "# check for response and status code of response\n",
    "print(f\"Website --> {response.url} has returned a response having status code --> {response.status_code}.\\\n",
    "\\nRead more about status code --> {config['status_code_info_url']}\")\n",
    "\n",
    "#  parsing the content returned by response\n",
    "\n",
    "# saving the response content in a html file\n",
    "with open(config[\"response_file_content\"], \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(response.text)\n",
    "\n",
    "print(f\"response content stored in {config['response_file_content']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing the response content to Beautifulsoup for parsing html data\n",
    "web_page = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"chakra-linkbox__overlay css-nzdyzb\" href=\"/jobs/yifxlruwe2-sr-product-analyst\"><style data-emotion=\"css 11xthxf\">.css-11xthxf{font-size:1rem;font-weight:600;}@media screen and (min-width: 30em){.css-11xthxf{font-size:1.125rem;}}</style><p class=\"chakra-text css-11xthxf\">Sr. Product Analyst</p></a>,\n",
       " <a class=\"chakra-linkbox__overlay css-nzdyzb\" href=\"/jobs/ixumzawhqq-data-engineer-data-ops\"><p class=\"chakra-text css-11xthxf\">Data Engineer / Data Ops</p></a>,\n",
       " <a class=\"chakra-linkbox__overlay css-nzdyzb\" href=\"/jobs/o6okkm0d0f-data-engineer\"><p class=\"chakra-text css-11xthxf\">Data Engineer</p></a>,\n",
       " <a class=\"chakra-linkbox__overlay css-nzdyzb\" href=\"/jobs/spxkdouo5t-senior-ml-engineer\"><p class=\"chakra-text css-11xthxf\">Senior ML Engineer</p></a>,\n",
       " <a class=\"chakra-linkbox__overlay css-nzdyzb\" href=\"/jobs/okmf74i1ul-staff-data-engineer\"><p class=\"chakra-text css-11xthxf\">Staff Data Engineer</p></a>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding required data from the parsed html content\n",
    "# Job Url <a tag> ---- it is the page where we will find all the related info\n",
    "job_url_class = \"chakra-linkbox__overlay css-nzdyzb\"\n",
    "job_url_class_tags = web_page.find_all('a',{'class':job_url_class})\n",
    "job_url_class_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job Title - Done\n",
    "# Company Name - Done\n",
    "# Location - Done\n",
    "# Tags or Skills - Done\n",
    "# Time Posted\n",
    "# Job Type - Done\n",
    "# Category - Done\n",
    "# Job Url - Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for first url\n",
    "profile_url = config[\"base_url\"] + job_url_class_tags[0][\"href\"]\n",
    "profile_url\n",
    "# get response from first url\n",
    "response_profile_url = requests.get(profile_url)\n",
    "# parse the text from url\n",
    "web_page_profile_url = BeautifulSoup(response_profile_url.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sr. Product Analyst']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Job Title\n",
    "lst_Job_Title = []\n",
    "job_title_class = \"chakra-text css-1j21cv6\"\n",
    "for job_title in web_page_profile_url.find_all('p',{'class':job_title_class}):\n",
    "    lst_Job_Title.append(job_title.text)\n",
    "\n",
    "lst_Job_Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boulevard']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comapany Name\n",
    "lst_Company_Name = []\n",
    "company_name_class = \"chakra-text css-0\"\n",
    "for company_name in web_page_profile_url.find_all('p',{'class':company_name_class}):\n",
    "    lst_Company_Name.append(company_name.text)\n",
    "\n",
    "lst_Company_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Full-Time']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Location, Job Type, Category\n",
    "lst_Location_Type_Category = []\n",
    "lst_Location = []\n",
    "lst_Job_Type = []\n",
    "lst_Category = []\n",
    "location_type_category_class = \"chakra-text css-10iahqc\"\n",
    "for location_type_category in web_page_profile_url.find_all('p',{'class':location_type_category_class}):\n",
    "    lst_Location_Type_Category.append(location_type_category.text)\n",
    "\n",
    "# lst_Location\n",
    "lst_Location.append(lst_Location_Type_Category[0])\n",
    "# lst_Job_Type\n",
    "lst_Job_Type.append(lst_Location_Type_Category[1])\n",
    "# lst_Category\n",
    "lst_Category.append(lst_Location_Type_Category[2])\n",
    "\n",
    "\n",
    "\n",
    "lst_Job_Type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['FiveTran', 'Healthcare', 'PostgreSQL', 'Python']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skills Tags\n",
    "lst_Skills_Tag = []\n",
    "profile_skills_tags = []\n",
    "skills_tag_class = \"css-1fogp5u\"\n",
    "for skills_tag in web_page_profile_url.find_all('span',{'class':skills_tag_class}):    \n",
    "    profile_skills_tags.append(skills_tag.text)\n",
    "    \n",
    "lst_Skills_Tag.append(profile_skills_tags)\n",
    "\n",
    "lst_Skills_Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping data for profile url: https://datastackjobs.com/jobs/yifxlruwe2-sr-product-analyst\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/ixumzawhqq-data-engineer-data-ops\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/o6okkm0d0f-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/spxkdouo5t-senior-ml-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/okmf74i1ul-staff-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/p1azjgcujr-marketing-manager\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/ojswkhzzy6-data-science-advocate\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/w45xlizshh-senior-data-scientist-product\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/q4cjm1n6fm-senior-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/vc3ynqb6l9-mlops-back-end-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/ni0frws4gc-cloud-infrastructure-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/edyq9egblg-senior-machine-learning-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/0pv3qxqcrp-senior-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/mbxbnw261d-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/vm5kgrooo4-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/qofsrtw71b-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/gfbanjlu0r-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/vhafue1wpc-sr-machine-learning-platform-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/akmffrpcy4-founding-staff-data-scientist\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/swcngss38o-senior-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/1ljwy3gxbl-senior-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/fchbtuibaq-senior-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/tcqcxesng3-marketing-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/v9ixdf791s-senior-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/nbocqtriis-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/2ol4g0m97m-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/ky7mcc3xto-staff-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/ioxpumdpes-sr-data-architect\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/mvu6rpdqac-software-architect-data-engineering\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/6buhpdbybz-senior-machine-learning-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/koiidhcdzb-data-engineering-team-lead\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/dbkesybeg4-senior-data-engineer-data-partnerships\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/xcveig27jo-senior-software-engineer-machine-learning\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/llojfrughh-big-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/aszhdkcr50-senior-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/mnay3mmpla-senior-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/di5wu0xfxn-machine-learning-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/j3bdjnckkd-senior-data-scientist\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/fviqfy4gvp-senior-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/x2rlhlnxdn-machine-learning-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/65mhjxbhkk-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/trz1dxqeps-senior-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/nzziqxbdfc-mlops-back-end-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/ecdbh7e98x-staff-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/cj2izg5kel-senior-data-analytics-developer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/r98pqk6xmc-data-science-internship\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/eyiizrzf6l-software-engineer-machine-learning\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/tbt87dznfc-senior-ml-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/wnnyq2wi9m-data-engineer\n",
      "Scrapping data for profile url: https://datastackjobs.com/jobs/h10gyqtkka-senior-data-engineer\n"
     ]
    }
   ],
   "source": [
    "lst_Company_Name = []\n",
    "lst_Job_Title = []\n",
    "lst_Location = []\n",
    "lst_Job_Type = []\n",
    "lst_Category = []\n",
    "lst_Skills_Tag = []\n",
    "lst_Job_Url = []\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def parse_website_datastacks_jobs(web_page_profile_url):\n",
    "    \n",
    "    # Comapany Name    \n",
    "    company_name_class = \"chakra-text css-0\"\n",
    "    for company_name in web_page_profile_url.find_all('p',{'class':company_name_class}):\n",
    "        lst_Company_Name.append(company_name.text)\n",
    "    \n",
    "    # Job Title\n",
    "    job_title_class = \"chakra-text css-1j21cv6\"\n",
    "    for job_title in web_page_profile_url.find_all('p',{'class':job_title_class}):\n",
    "        lst_Job_Title.append(job_title.text)\n",
    "\n",
    "    # Location, Job Type, Category\n",
    "    lst_Location_Type_Category = []\n",
    "    location_type_category_class = \"chakra-text css-10iahqc\"\n",
    "    for location_type_category in web_page_profile_url.find_all('p',{'class':location_type_category_class}):\n",
    "        lst_Location_Type_Category.append(location_type_category.text)\n",
    "    # lst_Location\n",
    "    lst_Location.append(lst_Location_Type_Category[0])\n",
    "    # lst_Job_Type\n",
    "    lst_Job_Type.append(lst_Location_Type_Category[1])\n",
    "    # lst_Category\n",
    "    lst_Category.append(lst_Location_Type_Category[2])\n",
    "\n",
    "    # Skills Tags\n",
    "    skills_tag_class = \"css-1fogp5u\"\n",
    "    profile_skills_tags = []\n",
    "    for skills_tag in web_page_profile_url.find_all('span',{'class':skills_tag_class}):\n",
    "        profile_skills_tags.append(skills_tag.text)\n",
    "        \n",
    "    lst_Skills_Tag.append(profile_skills_tags)\n",
    "\n",
    "\n",
    "# Job Url <a tag> ---- it is the page where we will find all the related info\n",
    "job_url_class = \"chakra-linkbox__overlay css-nzdyzb\"\n",
    "job_url_class_tags = web_page.find_all('a',{'class':job_url_class})\n",
    "\n",
    "# Parsing job urls\n",
    "for tags in job_url_class_tags:\n",
    "    profile_url = config[\"base_url\"] + tags[\"href\"]\n",
    "    print(f\"Scrapping data for profile url: {profile_url}\")\n",
    "    lst_Job_Url.append(profile_url)\n",
    "    # get response from profile url\n",
    "    response_profile_url = requests.get(profile_url)\n",
    "    # parse the text from profile url\n",
    "    web_page_profile_url = BeautifulSoup(response_profile_url.text,'html.parser')\n",
    "    parse_website_datastacks_jobs(web_page_profile_url)\n",
    "\n",
    "parsed_data_dict = {\"Company Name\":lst_Company_Name,\n",
    "                \"Job Title\":lst_Job_Title,\n",
    "                \"Location\":lst_Location,\n",
    "                \"Skill Tags\":lst_Skills_Tag,\n",
    "                \"Job Type\":lst_Job_Type,\n",
    "                \"Category\":lst_Category,\n",
    "                \"Job URL\":lst_Job_Url}\n",
    "\n",
    "parsed_data = pd.DataFrame(parsed_data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_Skills_Tag)\n",
    "# lst_Job_Title = []\n",
    "# lst_Location = []\n",
    "# lst_Job_Type = []\n",
    "# lst_Category = []\n",
    "# lst_Skills_Tag = []\n",
    "# lst_Job_Url = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data.head().to_csv(r'C:\\Test\\webscrapper.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the requests library to download web pages\n",
    "\n",
    "- Inspect the website's HTML source and identify the right URLs to download.\n",
    "- Download and save web pages locally using the requests library.\n",
    "- Create a function to automate downloading for different topics/search queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Beautiful Soup to parse and extract information\n",
    "\n",
    "- Parse and explore the structure of downloaded web pages using Beautiful soup.\n",
    "- Use the right properties and methods to extract the required information.\n",
    "- Create functions to extract from the page into lists and dictionaries.\n",
    "- (Optional) Use a REST API to acquire additional information if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV file(s) with the extracted information\n",
    "\n",
    "- Create functions for the end-to-end process of downloading, parsing, and saving CSVs.\n",
    "- Execute the function with different inputs to create a dataset of CSV files.\n",
    "- Verify the information in the CSV files by reading them back using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document and share your work\n",
    "\n",
    "- Add proper headings and documentation in your Jupyter notebook.\n",
    "- Publish your Jupyter notebook to your Jovian profile\n",
    "- (Optional) Write a blog post about your project and share it online.\n",
    "\n",
    "**Credit and Source** --> [**Jovian - Building a Python Web Scraping Project From Scratch**](https://jovian.ai/aakashns/python-web-scraping-project-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5cf268439eddf61ad37bad768a6371fa88c0de579168edb65ec6bbe41af8c40"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
