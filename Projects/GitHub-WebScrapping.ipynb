{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping GitHub Topics Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a website and describe your objective\n",
    "- Browse through different sites and pick on to scrape. Check the \"Project Ideas\" section for inspiration.\n",
    "- Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n",
    "- Summarize your project idea and outline your strategy in a Juptyer notebook. Use the \"New\" button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outline\n",
    "- Scrape website &#8594; https://datastackjobs.com\n",
    "- We will scrape the following content\n",
    "    - Company Name\n",
    "    - Job Title\n",
    "    - Location\n",
    "    - Tags or Skills\n",
    "    - Time Posted\n",
    "    - Job Type\n",
    "    - Category\n",
    "    - Job Url\n",
    "- We will then arrange the data in a tabular form and eport it to  CSV file\n",
    "- Output will look like\n",
    "\n",
    "Company Name,Job Title,Location,Tags or Skills,Time Posted,Job Type,Category,Job Url\n",
    "Boulevard,Sr. Product Analyst,United States. Remote,Amplitude | Mixpanel | SQL,a month ago,Full-Time,Product,https://datastackjobs.com/jobs/yifxlruwe2-sr-product-analyst\n",
    "\n",
    "Bitquery,Data Engineer/Data Ops,Worldwide . Remote,Airflow | Clickhouse | Apache Spark,2 months ago,Full-Time,Data Engineering,https://datastackjobs.com/jobs/ixumzawhqq-data-engineer-data-ops\n",
    "\n",
    "![datastack jobs](https://beeimg.com/images/i82872082642.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website --> https://datastackjobs.com/ has returned a response having status code --> 200.\n",
      "Read more about status code --> https://developer.mozilla.org/en-US/docs/Web/HTTP/Status\n",
      "response content stored in Web_Scrapping_content.html\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\"\"\"Import libraries if not then install them\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas\n",
    "import requests # to work with http and api requests\n",
    "from bs4 import BeautifulSoup # for parsing HTML, XML, JSON and other data\n",
    "\n",
    "# Config File\n",
    "config = {}\n",
    "config[\"base_url\"] = r\"https://datastackjobs.com\"\n",
    "config[\"status_code_info_url\"] = r\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status\"\n",
    "config[\"response_file_content\"] = \"Web_Scrapping_content.html\"\n",
    "\n",
    "# using requests library to fetch data from base_url\n",
    "response = requests.get(config[\"base_url\"])\n",
    "\n",
    "# check for response and status code of response\n",
    "print(f\"Website --> {response.url} has returned a response having status code --> {response.status_code}.\\\n",
    "\\nRead more about status code --> {config['status_code_info_url']}\")\n",
    "\n",
    "#  parsing the content returned by response\n",
    "\n",
    "# saving the response content in a html file\n",
    "with open(config[\"response_file_content\"], \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(response.text)\n",
    "\n",
    "print(f\"response content stored in {config['response_file_content']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing the response content to Beautifulsoup for parsing html data\n",
    "web_page = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"chakra-text css-11xthxf\">Sr. Product Analyst</p>,\n",
       " <p class=\"chakra-text css-11xthxf\">Data Engineer / Data Ops</p>,\n",
       " <p class=\"chakra-text css-11xthxf\">Data Engineer</p>,\n",
       " <p class=\"chakra-text css-11xthxf\">Senior ML Engineer</p>,\n",
       " <p class=\"chakra-text css-11xthxf\">Staff Data Engineer</p>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding required data from the parsed html content\n",
    "# Job Title\n",
    "job_title_class = \"chakra-text css-11xthxf\" # it is in p tag within an a tag\n",
    "job_title_tags = web_page.find_all('p',{'class': job_title_class})\n",
    "job_title_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Job Url\n",
    "company_name_class = \"chakra-text css-0\"\n",
    "company_class_tags = web_page.find_all('p',{'class':company_name_class})\n",
    "company_class_tags[:5]\n",
    "\n",
    "# Location\n",
    "# Tags or Skills\n",
    "# Time Posted\n",
    "# Job Type\n",
    "# Category\n",
    "# Job Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the requests library to download web pages\n",
    "\n",
    "- Inspect the website's HTML source and identify the right URLs to download.\n",
    "- Download and save web pages locally using the requests library.\n",
    "- Create a function to automate downloading for different topics/search queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Beautiful Soup to parse and extract information\n",
    "\n",
    "- Parse and explore the structure of downloaded web pages using Beautiful soup.\n",
    "- Use the right properties and methods to extract the required information.\n",
    "- Create functions to extract from the page into lists and dictionaries.\n",
    "- (Optional) Use a REST API to acquire additional information if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV file(s) with the extracted information\n",
    "\n",
    "- Create functions for the end-to-end process of downloading, parsing, and saving CSVs.\n",
    "- Execute the function with different inputs to create a dataset of CSV files.\n",
    "- Verify the information in the CSV files by reading them back using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document and share your work\n",
    "\n",
    "- Add proper headings and documentation in your Jupyter notebook.\n",
    "- Publish your Jupyter notebook to your Jovian profile\n",
    "- (Optional) Write a blog post about your project and share it online.\n",
    "\n",
    "**Credit and Source** --> [**Jovian - Building a Python Web Scraping Project From Scratch**](https://jovian.ai/aakashns/python-web-scraping-project-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5cf268439eddf61ad37bad768a6371fa88c0de579168edb65ec6bbe41af8c40"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
